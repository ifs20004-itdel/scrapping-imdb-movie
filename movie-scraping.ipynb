{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate any global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_title = []\n",
    "movies_sinopsis = []\n",
    "movies_rating = []\n",
    "movies_genre = []\n",
    "\n",
    "# Free to adjust, because the total data of the website is about 19.000 film,\n",
    "# it will be time consuming to process all the data, we gave the limit till 1000\n",
    "max_data = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request from your page source (ImDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded:  100\n",
      "Already loaded 100 items. Stopping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://www.imdb.com/search/title/?title_type=feature,tv_series&count=100&sort=num_votes,desc\"\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "# Ensure you have the appropriate WebDriver installed\n",
    "driver = webdriver.Chrome()  \n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load completely (atur sleep duration sesuai kemampuan/kecepatan internet)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Initial display data\n",
    "data_loaded = 100\n",
    "while True:\n",
    "    try:\n",
    "        print(\"data loaded: \", data_loaded)\n",
    "        if data_loaded >= max_data:\n",
    "            print(f\"Already loaded {data_loaded} items. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Locate the \"Load More\" button\n",
    "        load_more_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'ipc-see-more__text')))  \n",
    "\n",
    "        ActionChains(driver).move_to_element(load_more_button).click(load_more_button).perform()\n",
    "\n",
    "        # Wait for new content to load\n",
    "        time.sleep(2)  \n",
    "        data_loaded += 100\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"No more data to load or error:\", e)\n",
    "        break  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to extract data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa006653ea04c1a81f38ebac59d1221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 101 100\n"
     ]
    }
   ],
   "source": [
    "# Get the rendered page source\n",
    "html_source = driver.page_source\n",
    "soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "print(\"Begin to extract data\")\n",
    "# Progress Bar\n",
    "f = IntProgress(min=0, max=max_data)\n",
    "display(f)\n",
    "\n",
    "# # Element to be scrapping: titles, rating, sinopsis\n",
    "titles = soup.find_all('h3', class_=\"ipc-title__text\")\n",
    "sinopsis = soup.find_all('div', class_ = \"ipc-html-content-inner-div\")\n",
    "rating = soup.find_all('span','ipc-rating-star--rating')\n",
    "print(len(rating), len(titles), len(sinopsis))\n",
    "\n",
    "info_buttons = driver.find_elements(By.CLASS_NAME, 'ipc-icon-button.dli-info-icon')\n",
    "\n",
    "# Loop through each button to find genre\n",
    "for index, button in enumerate(info_buttons):\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable(button))\n",
    "        ActionChains(driver).move_to_element(button).click(button).perform()\n",
    "        modal = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, \"ipc-promptable-base__panel\")))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Got the genre data\n",
    "        list_items = driver.find_elements(By.XPATH, \"//ul[@data-testid='btp_gl']//li[@class='ipc-inline-list__item']\")\n",
    "        categories = [item.text for item in list_items]\n",
    "        movies_genre.append(categories)\n",
    "\n",
    "        # Close the modal after performing actions\n",
    "        close_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'ipc-promptable-base__close')))\n",
    "        close_button.click()\n",
    "\n",
    "        # Update progress bar\n",
    "        f.value +=1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking button {index + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the selenium browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movie title\n",
    "for i in titles:\n",
    "    text = i.text.strip()\n",
    "    if text[0].isdigit():     \n",
    "        title = text.split(\".\")[1]\n",
    "        movies_title.append(title)\n",
    "len(movies_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sinopsis\n",
    "for i in sinopsis:\n",
    "    text  = i.text.strip()\n",
    "    movies_sinopsis.append(text)\n",
    "len(movies_sinopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating\n",
    "for i in rating:\n",
    "    text = i.text.strip()\n",
    "    movies_rating.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceed Cleaned Data into JSON/CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to movies2.csv\n",
      "Data successfully saved to movies2.json\n"
     ]
    }
   ],
   "source": [
    "# Ensure both arrays have the same length\n",
    "# Make sure the lenght of each data the same.\n",
    "movies_title_fixed = movies_title[:max_data]\n",
    "movies_sinopsis_fixed = movies_sinopsis[:max_data]\n",
    "movies_rating_fixed = movies_rating[:max_data]\n",
    "movies_genre_fixed= movies_genre[:max_data]\n",
    "\n",
    "\n",
    "if len(movies_title) != len(movies_sinopsis):\n",
    "    print(\"Error: Arrays must have the same length.\")\n",
    "else:\n",
    "    data = {\"title\": movies_title_fixed, \"sinopsis\": movies_sinopsis_fixed, \"rating\": movies_rating_fixed, \"genre\": movies_genre_fixed}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_filename = \"movies.csv\"\n",
    "    df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Data successfully saved to {csv_filename}\")\n",
    "\n",
    "    # Save to JSON\n",
    "    json_filename = \"movies.json\"\n",
    "    df.to_json(json_filename, orient=\"records\", lines=False, force_ascii=False)\n",
    "    print(f\"Data successfully saved to {json_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
